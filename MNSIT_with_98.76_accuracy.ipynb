{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNSIT with 98.76 %accuracy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+wP5Tkgr4tXX8zeLr+4HU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVpO7EW4ifX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "b08a24ad-e237-4005-84a7-70b78f798773"
      },
      "source": [
        "#Importing All required Library\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.layers import Conv2D,Flatten,MaxPooling2D,Dense,Dropout,BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Specify 'channels_first' to be the dimension ordering convention Keras will follow.\n",
        "tf.keras.backend.set_image_data_format('channels_first')\n",
        "\n",
        "# Load dataset (download if needed)\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "#Extracting the validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_val, y_train,y_val = train_test_split(X_train,y_train,test_size=.3)\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD7CAYAAAAVQzPHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYflpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIYTCa6u34Sf",
        "colab_type": "text"
      },
      "source": [
        "#Pre-processing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH5FVXl-3whX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],1,28,28).astype('float64')\n",
        "X_val = X_val.reshape(X_val.shape[0],1,28,28).astype('float64')\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "\n",
        "#one hot encoding output y\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "#total number of classes \n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "#input shape\n",
        "rows = X_train.shape[2]\n",
        "cols = X_train.shape[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWN4hI_SYwYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(rotation_range=10,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.1)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(X_train,augment=True)\n",
        "\n",
        "# get transformed images\n",
        "train_size = X_train.shape[0]\n",
        "augment_size=42000\n",
        "randidx = np.random.randint(train_size, size=augment_size)\n",
        "X_augmented = X_train[randidx].copy()\n",
        "y_augmented = y_train[randidx].copy()\n",
        "X_augmented = datagen.flow(X_augmented, np.zeros(augment_size),\n",
        "                                    batch_size=augment_size, shuffle=False).next()[0]\n",
        "\n",
        "# append augmented data to trainset\n",
        "X_train = np.concatenate((X_train, X_augmented))\n",
        "y_train = np.concatenate((y_train, y_augmented))\n",
        "train_size = X_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGzLkCyt3UE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining a baseline model\n",
        "\n",
        "def baseline_model():\n",
        "    model = tf.keras.Sequential([\n",
        "                                 Conv2D(32,kernel_size=3,activation='relu',input_shape=(1,rows,cols)),\n",
        "                                 BatchNormalization(),\n",
        "                                 Conv2D(32,kernel_size=3,activation='relu'),\n",
        "                                 BatchNormalization(),\n",
        "                                 Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dropout(0.4),\n",
        "\n",
        "                                 Conv2D(64,kernel_size=3,activation='relu'),\n",
        "                                 BatchNormalization(),\n",
        "                                 Conv2D(64,kernel_size=3,activation='relu'),\n",
        "                                 BatchNormalization(),\n",
        "                                 Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dropout(0.4),\n",
        "\n",
        "                                 Flatten(),\n",
        "                                 Dense(128,activation='relu'),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dropout(0.4),\n",
        "                                 Dense(num_classes,activation='softmax')\n",
        "                                ]) \n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69QiHZ3n_eGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "563e43f1-2ec0-48f5-f72d-670806567d57"
      },
      "source": [
        "#Build a model\n",
        "\n",
        "model = baseline_model()\n",
        "BATCH_SIZE=32\n",
        "#Train the model\n",
        "model.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=BATCH_SIZE,epochs=50, verbose=2)\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 26, 26)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 32, 26, 26)        104       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 24, 24)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 32, 24, 24)        96        \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 32, 12, 12)        25632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 32, 12, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32, 12, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 64, 10, 10)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 64, 10, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 64, 8, 8)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 64, 8, 8)          32        \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 64, 4, 4)          102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 64, 4, 4)          16        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64, 4, 4)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 326,426\n",
            "Trainable params: 326,002\n",
            "Non-trainable params: 424\n",
            "_________________________________________________________________\n",
            "Train on 84000 samples, validate on 18000 samples\n",
            "Epoch 1/50\n",
            "84000/84000 - 18s - loss: 0.2600 - accuracy: 0.9207 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
            "Epoch 2/50\n",
            "84000/84000 - 17s - loss: 0.0837 - accuracy: 0.9750 - val_loss: 0.0333 - val_accuracy: 0.9908\n",
            "Epoch 3/50\n",
            "84000/84000 - 17s - loss: 0.0632 - accuracy: 0.9807 - val_loss: 0.0325 - val_accuracy: 0.9908\n",
            "Epoch 4/50\n",
            "84000/84000 - 16s - loss: 0.0498 - accuracy: 0.9851 - val_loss: 0.0307 - val_accuracy: 0.9917\n",
            "Epoch 5/50\n",
            "84000/84000 - 16s - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.0337 - val_accuracy: 0.9906\n",
            "Epoch 6/50\n",
            "84000/84000 - 17s - loss: 0.0362 - accuracy: 0.9894 - val_loss: 0.0254 - val_accuracy: 0.9933\n",
            "Epoch 7/50\n",
            "84000/84000 - 17s - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0304 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "84000/84000 - 17s - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0234 - val_accuracy: 0.9941\n",
            "Epoch 9/50\n",
            "84000/84000 - 16s - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0217 - val_accuracy: 0.9948\n",
            "Epoch 10/50\n",
            "84000/84000 - 16s - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0297 - val_accuracy: 0.9928\n",
            "Epoch 11/50\n",
            "84000/84000 - 16s - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0232 - val_accuracy: 0.9948\n",
            "Epoch 12/50\n",
            "84000/84000 - 16s - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0290 - val_accuracy: 0.9932\n",
            "Epoch 13/50\n",
            "84000/84000 - 16s - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0295 - val_accuracy: 0.9936\n",
            "Epoch 14/50\n",
            "84000/84000 - 16s - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0307 - val_accuracy: 0.9926\n",
            "Epoch 15/50\n",
            "84000/84000 - 16s - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0297 - val_accuracy: 0.9927\n",
            "Epoch 16/50\n",
            "84000/84000 - 16s - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.0252 - val_accuracy: 0.9945\n",
            "Epoch 17/50\n",
            "84000/84000 - 16s - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0275 - val_accuracy: 0.9941\n",
            "Epoch 18/50\n",
            "84000/84000 - 16s - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0219 - val_accuracy: 0.9952\n",
            "Epoch 19/50\n",
            "84000/84000 - 16s - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0307 - val_accuracy: 0.9938\n",
            "Epoch 20/50\n",
            "84000/84000 - 16s - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0299 - val_accuracy: 0.9938\n",
            "Epoch 21/50\n",
            "84000/84000 - 16s - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0260 - val_accuracy: 0.9937\n",
            "Epoch 22/50\n",
            "84000/84000 - 16s - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0247 - val_accuracy: 0.9954\n",
            "Epoch 23/50\n",
            "84000/84000 - 16s - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0270 - val_accuracy: 0.9943\n",
            "Epoch 24/50\n",
            "84000/84000 - 16s - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0321 - val_accuracy: 0.9933\n",
            "Epoch 25/50\n",
            "84000/84000 - 16s - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0304 - val_accuracy: 0.9943\n",
            "Epoch 26/50\n",
            "84000/84000 - 16s - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0302 - val_accuracy: 0.9936\n",
            "Epoch 27/50\n",
            "84000/84000 - 17s - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0283 - val_accuracy: 0.9946\n",
            "Epoch 28/50\n",
            "84000/84000 - 17s - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0248 - val_accuracy: 0.9952\n",
            "Epoch 29/50\n",
            "84000/84000 - 16s - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0290 - val_accuracy: 0.9944\n",
            "Epoch 30/50\n",
            "84000/84000 - 16s - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0281 - val_accuracy: 0.9946\n",
            "Epoch 31/50\n",
            "84000/84000 - 17s - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0312 - val_accuracy: 0.9941\n",
            "Epoch 32/50\n",
            "84000/84000 - 17s - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0272 - val_accuracy: 0.9951\n",
            "Epoch 33/50\n",
            "84000/84000 - 16s - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0277 - val_accuracy: 0.9951\n",
            "Epoch 34/50\n",
            "84000/84000 - 16s - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0274 - val_accuracy: 0.9952\n",
            "Epoch 35/50\n",
            "84000/84000 - 16s - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0252 - val_accuracy: 0.9952\n",
            "Epoch 36/50\n",
            "84000/84000 - 16s - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0298 - val_accuracy: 0.9944\n",
            "Epoch 37/50\n",
            "84000/84000 - 16s - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0295 - val_accuracy: 0.9953\n",
            "Epoch 38/50\n",
            "84000/84000 - 16s - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0309 - val_accuracy: 0.9945\n",
            "Epoch 39/50\n",
            "84000/84000 - 16s - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0291 - val_accuracy: 0.9945\n",
            "Epoch 40/50\n",
            "84000/84000 - 16s - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0302 - val_accuracy: 0.9947\n",
            "Epoch 41/50\n",
            "84000/84000 - 16s - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0324 - val_accuracy: 0.9948\n",
            "Epoch 42/50\n",
            "84000/84000 - 16s - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0379 - val_accuracy: 0.9938\n",
            "Epoch 43/50\n",
            "84000/84000 - 17s - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0303 - val_accuracy: 0.9945\n",
            "Epoch 44/50\n",
            "84000/84000 - 16s - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0311 - val_accuracy: 0.9947\n",
            "Epoch 45/50\n",
            "84000/84000 - 16s - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0305 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "84000/84000 - 17s - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0291 - val_accuracy: 0.9952\n",
            "Epoch 47/50\n",
            "84000/84000 - 16s - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0303 - val_accuracy: 0.9945\n",
            "Epoch 48/50\n",
            "84000/84000 - 16s - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0376 - val_accuracy: 0.9939\n",
            "Epoch 49/50\n",
            "84000/84000 - 16s - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0289 - val_accuracy: 0.9948\n",
            "Epoch 50/50\n",
            "84000/84000 - 16s - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0280 - val_accuracy: 0.9948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--VOcFksOdzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6c76a513-684c-4ba9-8011-d57f93bc4529"
      },
      "source": [
        "# Final eval\n",
        "X_test1 = X_test.reshape(X_test.shape[0],1,28,28).astype('float64')\n",
        "y_test1 = to_categorical(y_test)\n",
        "\n",
        "scores = model.evaluate(X_test1, y_test1,verbose=1)\n",
        "print(\"CNN error: %.2f%%\" % (100 - scores[1]*100))\n",
        "print(\"CNN accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 128us/sample - loss: 2.8237 - accuracy: 0.9876\n",
            "CNN error: 1.24%\n",
            "CNN accuracy: 98.76%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}